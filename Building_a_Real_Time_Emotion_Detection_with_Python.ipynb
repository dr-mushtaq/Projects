{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Projects-/blob/master/Building_a_Real_Time_Emotion_Detection_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS"
      },
      "source": [
        "# Building a Real Time Emotion Detection with Python\n",
        "# **Introduction:**\n",
        "\n",
        "Detecting real-time emotion of the person with a camera input is one of the advanced features in the machine learning process. The detection of emotion of a person using a camera is useful for various research and analytics purposes. The detection of emotion is made by using the machine learning concept. You can use the trained dataset to detect the emotion of the human being. For detecting the different emotions, first you need to train those different emotions, or you can use a dataset already available on the internet. In this article, we will discuss creating a Python program to detect real-time emotion of a human being using the camera '[1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAVZc4ayyDWL"
      },
      "source": [
        "# 1-Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpWN1sJv8eho",
        "outputId": "b09ba454-dd8b-44b1-91ea-8b165d079a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWA9EJ-zwyej"
      },
      "source": [
        "!pip install tensor flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6X6cfXcw4uL",
        "outputId": "3a7e31d5-f028-4e75-daae-b4095ecc7eb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le9Nov-7w7X6"
      },
      "source": [
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFMnGbhH9sIS"
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Pia2KM9x9d"
      },
      "source": [
        "!pip install adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnF8AVoy93tt"
      },
      "source": [
        "!pip install kwargs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy8GBKBY99lX"
      },
      "source": [
        "!pip install cinit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnY7VuCDI-qN"
      },
      "source": [
        "# 1 **Training the Dataset**#\n",
        "\n",
        "For training purposes, I use the predefined un trained dataset CSV file as my main input for my input for training the machine. You can use the code given below for training the machine using the dataset. Before that, you need to ensure that all required files in the same repository where the program presents otherwise it will through some error. You can download the data set by clicking here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf"
      },
      "source": [
        "# 2 - **Import library**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfWGnlhx_GYu",
        "outputId": "22786b22-1b51-4fbe-f146-cb4d85039262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQFJb0YzEYO"
      },
      "source": [
        "#2 - **Load Dataset** #\n",
        "The both training and evaluation operations would be handled with Fec2013 dataset. Compressed version of the dataset takes 92 MB space whereas uncompressed version takes 295 MB space. There are 28K training and 3K testing images in the dataset. Each image was stored as 48×48 pixel. The pure dataset consists of image pixels (48×48=2304 values), emotion of each image and usage type (as train or test instance)[2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hncBMFUXFN6G",
        "outputId": "84c2788f-3f6b-4618-8062-356efc144f49",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# this code is used to upload dataset from Pc to colab\n",
        "from google.colab import files # Please First run this cod in chrom\n",
        "def getLocalFiles():\n",
        "    _files = files.upload() # upload StudentNextSessionf.csv datase\n",
        "    if len(_files) >0: # Then run above  libray\n",
        "       for k,v in _files.items():\n",
        "         open(k,'wb').write(v)\n",
        "getLocalFiles()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-13a50f87-6a08-414d-b170-b5f790de68c7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-13a50f87-6a08-414d-b170-b5f790de68c7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving la.jfif to la.jfif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPlEL8_ADW3F"
      },
      "source": [
        "!wget -N https://www.kaggle.com/deadskull7/fer2013"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqD8iiJZzTZj"
      },
      "source": [
        "df=pd.read_csv('fer2013.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpHsrVexXuWj"
      },
      "source": [
        "#2-Data Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia4AAHlC6Mhb"
      },
      "source": [
        "print(df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS0gKFmiHAvq"
      },
      "source": [
        "print(df[\"Usage\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zimrlUU8HEy3"
      },
      "source": [
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL"
      },
      "source": [
        "# 3- **Data Spliting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq"
      },
      "source": [
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6333A5woSWX_"
      },
      "source": [
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "width, height = 48, 48"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsFBKUfkSYeB"
      },
      "source": [
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcTmmZATSh5k"
      },
      "source": [
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q"
      },
      "source": [
        "#4- **Normalizing data between 0 and 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy"
      },
      "source": [
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-"
      },
      "source": [
        "# 5- **Designing the CNN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrgUo8fTbXz"
      },
      "source": [
        "##5.1- **1st convolution layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF"
      },
      "source": [
        "## 5.2 - **2nd Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW"
      },
      "source": [
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLfUeKr2UNe7"
      },
      "source": [
        "## 5.3- **3rd Convolution Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUJ16arHaKMT"
      },
      "source": [
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7EabEFjUl6t"
      },
      "source": [
        "##5.4-  **Fully connected neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_XHGn_oUvMG"
      },
      "source": [
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-DCjB-Io3j7"
      },
      "source": [
        "#**6-Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_1M1FnMN2O"
      },
      "source": [
        "##**6.1 Method1 Generator [2]**\n",
        "We can train the network. To complete the training in less time, I prefer to implement learning with randomly selected trainset instances. That is the reason why train and fit generator used. Also, loss function would be cross entropy because the task is multi class classification [2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc_KJ0lWlm8W"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import SGD\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1KyuvVXMRbr"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(X_train, train_y, batch_size=batch_size)\n",
        "model.compile(loss='categorical_crossentropy'\n",
        ", optimizer=keras.optimizers.Adam()\n",
        ", metrics=['accuracy']\n",
        ")\n",
        "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOCxPs8sU5aP"
      },
      "source": [
        "##6.2-**Method 2 Compliling the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi-DFb_OVBr4"
      },
      "source": [
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02q29lEXVRjz"
      },
      "source": [
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKCwzVMnVaOm"
      },
      "source": [
        "#7-**Saving the  model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-PUeUv-VglW"
      },
      "source": [
        "fer_json = model.to_json()\n",
        "with open(\"fer.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtpS-joPfJqi"
      },
      "source": [
        "#8-**Evaluate model [2]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S05tU0VfhVm"
      },
      "source": [
        "train_score = model.evaluate(X_train, train_y, verbose=0)\n",
        "print('Train loss:', train_score[0])\n",
        "print('Train accuracy:', 100*train_score[1])\n",
        "test_score = model.evaluate(X_test, test_y, verbose=0)\n",
        "print('Test loss:', test_score[0])\n",
        "print('Test accuracy:', 100*test_score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UC9kS_Rv_hA"
      },
      "source": [
        "# **9-Confusion Matrix**[2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmsbOnwbwJTN"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "pred_list = []; actual_list = []\n",
        "\n",
        "for i in predictions:\n",
        "  pred_list.append(np.argmax(i))\n",
        "\n",
        "for i in Y_test:\n",
        "  actual_list.append(np.argmax(i))\n",
        "\n",
        "confusion_matrix(actual_list, pred_list)\n",
        "Testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8WWRWP0wh2Z"
      },
      "source": [
        "#**10-Testing**[2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjDLBzNZw7Tf",
        "outputId": "d861f283-6eaf-45de-e6d0-a3112c679f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from matplotlib import pyplot as plt\n",
        "img = image.load_img(\"la.jfif\", grayscale=True, target_size=(48, 48))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "x /= 255\n",
        "custom = model.predict(x)\n",
        "emotion_analysis(custom[0])\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "plt.gray()\n",
        "plt.imshow(x)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
            "  warnings.warn('grayscale is deprecated. Please use '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Te0y5lxDan"
      },
      "source": [
        "Emotions stored as numerical as labeled from 0 to 6. Keras would produce an output array including these 7 different emotion scores. We can visualize each prediction as bar chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyQL0kDKwyxm"
      },
      "source": [
        "def emotion_analysis(emotions):\n",
        "  objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "  y_pos = np.arange(len(objects))\n",
        "  plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
        "  plt.xticks(y_pos, objects)\n",
        "  plt.ylabel('percentage')\n",
        "  plt.title('emotion')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNk8Y4m5b3tf"
      },
      "source": [
        "#**11-Detecting Real-Time Emotion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgAXg8iCb88r"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJbt4FopcEyh"
      },
      "source": [
        "#load model\n",
        "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
        "#load weights\n",
        "model.load_weights('fer.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb9gAA3fcMGx"
      },
      "source": [
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srFH4QN7cNW8"
      },
      "source": [
        "cap=cv2.VideoCapture(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxitWGrYcUIS"
      },
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "while True:\n",
        "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
        "    #if not ret:\n",
        "        #continue\n",
        "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
        "\n",
        "\n",
        "    for (x,y,w,h) in faces_detected:\n",
        "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
        "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
        "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "        img_pixels = image.img_to_array(roi_gray)\n",
        "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "        img_pixels /= 255\n",
        "\n",
        "        predictions = model.predict(img_pixels)\n",
        "\n",
        "        #find max indexed array\n",
        "        max_index = np.argmax(predictions[0])\n",
        "\n",
        "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "        predicted_emotion = emotions[max_index]\n",
        "\n",
        "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "\n",
        "    resized_img = cv2.resize(test_img, (1000, 700))\n",
        "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei"
      },
      "source": [
        "References:\n",
        "\n",
        "[1] Building a Real Time Emotion Detection with Python\n",
        "\n",
        "https://morioh.com/p/801c509dda99?f=5c21f93bc16e2556b555ab2f\n",
        "\n",
        "[2] Facial Expression Recognition with Keras\n",
        "http://sefiks.com/2018/01/01/facial-expression-recognition-with-keras/\n",
        "\n",
        "[3] Machine Learning Project | Facial Emotion Detection | part 2 Creating Webapp using Flask\n",
        "\n",
        "https://www.youtube.com/watch?v=2mN7ygkc2XU&feature=youtu.be&fbclid=IwAR35sBAYwEakprFrmi12-4wW_54COtb8hcXdEdlCJjQ_en2JCi4zRA28bSs\n",
        "\n"
      ]
    }
  ]
}